{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import h5py\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /data4/wuxc/software/anaconda/lib/python3.8/site-packages (1.19.2)\n",
      "Requirement already satisfied: scikit-learn in /data4/wuxc/software/anaconda/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data4/wuxc/software/anaconda/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /data4/wuxc/software/anaconda/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /data4/wuxc/software/anaconda/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install scanpy\n",
    "# %pip install anndata\n",
    "# %pip install lightgbm\n",
    "# %pip install numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/home/wuxc/data/open_multiome_compete/data/\"\n",
    "CELL_METADATA = os.path.join(DATA_DIR, \"metadata.csv\")\n",
    "CITE_TRAIN_INPUTS = os.path.join(DATA_DIR, \"train_cite_inputs.h5\")\n",
    "CITE_TRAIN_TARGETS = os.path.join(DATA_DIR, \"train_cite_targets.h5\")\n",
    "CITE_TEST_INPUTS = os.path.join(DATA_DIR, \"test_cite_inputs.h5\")\n",
    "\n",
    "MULTIOME_TRAIN_INPUTS = os.path.join(DATA_DIR, \"train_multi_inputs.h5\")\n",
    "MULTIOME_TRAIN_TARGETS = os.path.join(DATA_DIR, \"train_multi_targets.h5\")\n",
    "MULTIOME_TEST_INPUTS = os.path.join(DATA_DIR, \"test_multi_inputs.h5\")\n",
    "\n",
    "SUBMISSION = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "EVALUATION_IDS = os.path.join(DATA_DIR, \"evaluation_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119651, 5), (161877, 5))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cell = pd.read_csv(CELL_METADATA)\n",
    "df_cell_cite = df_cell[df_cell.technology==\"citeseq\"]\n",
    "df_cell_multi = df_cell[df_cell.technology==\"multiome\"]\n",
    "df_cell_cite.shape, df_cell_multi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess for CITEseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "col_start = 10000\n",
    "\n",
    "class PreprocessCiteseq(BaseEstimator, TransformerMixin):\n",
    "    columns_to_use = 13000\n",
    "\n",
    "    @staticmethod\n",
    "    def take_columnn_subset(X):\n",
    "        return X[:, -(PreprocessCiteseq.columns_to_use + col_start):-col_start]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print(X.shape)\n",
    "        X = X[:, ~self.all_zero_columns]\n",
    "        print(X.shape)\n",
    "        X = PreprocessCiteseq.take_column_subset(X)\n",
    "        print(X.shape)\n",
    "        gc.collect()\n",
    "\n",
    "        X = self.pca.transform(X)\n",
    "        print(X.shape)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        gc.collect()\n",
    "        print(X.shape)\n",
    "        self.all_zero_columns = (X == 0).all(axis=0)\n",
    "        X = X[:, ~self.all_zero_columns]\n",
    "        print(X.shape)\n",
    "        X = PreprocessCiteseq.take_column_subset(X)\n",
    "        print(X.shape)\n",
    "        gc.collect()\n",
    "\n",
    "        self.pca = PCA(n_components=240, copy=False, random_state=1)\n",
    "        X = self.pca.fit_transform(X)\n",
    "        print(X.shape)\n",
    "        return X\n",
    "\n",
    "preprocesser = PreprocessCiteseq()\n",
    "cite_train_x = None\n",
    "cite_train_x = preprocesser.fit_transform(pd.read_hdf(CITE_TRAIN_INPUTS).values)\n",
    "\n",
    "cite_train_y = pd.read_hdf(CITE_TRAIN_TARGETS).values\n",
    "print(cite_train_x.shape, cite_train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.5,\n",
    "    'metric': 'mae',\n",
    "    'seed': 42,\n",
    "    'reg_alpha': 0.0014,\n",
    "    'reg_lambda': 0.2,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'num_leaves': 722,\n",
    "    'min_child_samples': 85,\n",
    "}\n",
    "\n",
    "model = MultiOutputRegressor(lgb.LGBMRegressor(**params, n_estimators=1000))\n",
    "print(\"fitting\")\n",
    "model.fit(cite_train_x, cite_train_y)\n",
    "print(\"fit proces done\")\n",
    "\n",
    "y_va_pred = model.predict(cite_train_x)\n",
    "mse = mean_squared_error(cite_train_y, y_va_pred)\n",
    "print(mse)\n",
    "del cite_train_x, cite_train_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_test_x = preprocesser.transform(pd.read_hdf(CITE_TEST_INPUTS).values)\n",
    "test_pred = model.predict(cite_test_x)\n",
    "del cite_test_x\n",
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene expression embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 285 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch\n",
    "%pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5,5,5,5)\n",
    "y = torch.randn(5,5,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.einsum('b c h w -> b*w c h',x)\n",
    "torch.einsum('b k h w, b k h w -> b h w', x, y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20, 50])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10,20,30) # b -> 10, i -> 20, k -> 30\n",
    "c = torch.randn(10,50,30) # b -> 10, j -> 50, k -> 30\n",
    "y1 = torch.einsum('b i k, b j k -> b i j', a , c) # shape [10, 20, 50]\n",
    "print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 100, 1000]) torch.Size([10, 100, 1000]) torch.Size([10, 100, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 100, 1000) # batch, tokens, dim\n",
    "dim = 1000 ## simulated # of gene\n",
    "to_qkv = nn.Linear(dim, dim*3, bias=False) ## init qkv matrix\n",
    "qkv = to_qkv(x) ## x is the gene expression embedding vector\n",
    "q, k, v = tuple(rearrange(qkv, 'b t (d k) -> k b t d', k=3))\n",
    "print(q.shape, k.shape, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "572335ad3da9c77a4135952a92effa558a40d2f4eaa654bf4ee2808539357962"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
